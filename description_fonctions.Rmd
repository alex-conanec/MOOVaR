---
title: "Estimation des quantiles conditionnels"
author: "Alexandre Conanec"
header-includes:
   - \usepackage{bbold}
date: "January 8, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(condQuant)
```

$$
\DeclareMathOperator*{\argmax}{arg\!\max}
\DeclareMathOperator*{\argmin}{arg\!\min}
$$

##Défintions
On défini le quantile conditionnels 

$$
\begin{equation}
    \label{def_quantile_cond}
    q_\alpha(x) = \inf\{y | F(y|x) \geq \alpha\} = F^{-1}(y|x) .
\end{equation} 
$$
On estime $q_\alpha(x)$ par $q_{\alpha, n}(x)$

$$
\begin{equation}
    \label{estimation_quantile_cond}
    q_{\alpha, n}(x) = F_n^{-1}(y|x) = \inf\{y | F_n(y|x) \geq \alpha\} ,
\end{equation} 
$$
où $F$ est estimé par $F_n$ par une méthode de noyau 

$$
\begin{equation}
    \label{estimation_Fn}
    F_n(y|x) = (\sum\limits_{i = 1}^{n} \frac{K(x - {\bf x}_i)}{h_n})^{-1}
    \sum\limits_{i = 1}^{n} \frac{K(x - {\bf x}_i)}{h_n} \mathbb{1}_{\{{\bf y}_i \leq y\}} ,
\end{equation}
$$
où $K=\sqrt(2\pi)^{-k} e^{-\sum\limits_{i=1}^n \frac{x_i^2}{2}}$

###Petit example simulé

```{r}
#simu données k=1
set.seed(258164)
n <- 300
X <- runif(n = n, min = -2, max = 2)
Y <- X^2 + rnorm(n)

#parametres
alpha <- 0.1
h_n <- 0.2

#estimation de q_n et calcul de q
x_range <- seq(-2, 2, length.out = n/2)
parallel::mclapply(x_range, function(x){
  q <- qnorm(p = alpha, mean = x^2, sd = 1)
  q_n <- conditionnal_quantile(X, Y, x, alpha, h_n = h_n)
  data.frame(q=q, q_n=q_n)
}, mc.cores = 8) %>% bind_rows()-> res

#plot
res <- cbind(x_range = x_range, res) %>% 
  gather(key = key, value = value, -x_range)
data <- cbind(data.frame(X=X, Y=Y), res) 

ggplot(data) +
  geom_point(aes(x=X, y=Y)) +
  geom_line(aes(x=x_range, y=value, col = key))
```

##Fonction de tunage du $h_n$

Essayons maintenant d'estimer la valeur optimale $h_n^*$ par validation croisé 

$$
\begin{equation}
  h_n^* = \argmin_{h>0} \sum\limits_{t=1}^n \int_\mathbb{R} 
    [\mathbb{1}_{\{Y_t \leq y\}} - F_{n,t}(y|x)]^2 \omega(y)dy. 
\end{equation}
$$
Cette valeur optimal de $h_n^*$ peut donc être estimée à partir de $\bf X$ et $\bf Y$.
Prenons le temps de décomposer chaque partie de cette estimation.

$$
\begin{equation}
  \omega(u) = \frac{1}{2} \mathbb{1}_{\{|u| \leq 1\}} 
\end{equation}
$$
est un noyau uniforme. Le probleme est qu'il est directement appliqué à $y$, et non à un eloignement 


$$
\begin{equation}
  \begin{array}{r@{}l}
    F_{n,t}(x|y) = (\sum\limits_{i\in S} \frac{K(x - X_i)}{h_n})^{-1}
    \sum\limits_{i\in S} \frac{K(x - X_i)}{h_n} \mathbb{1}_{\{Y_i \leq y\}},\\ 
    S = \{i \in \mathbb{N} | 1 \leq i \leq n\ et\ i \neq t\}
  \end{array}
\end{equation}
$$


$$
\begin{equation}
  A_{n,t}(y, x) = [\mathbb{1}_{\{Y_t \leq y\}} - F_{n, t}(y|x)]^2 \omega(y) 
\end{equation}
$$
$$
\begin{equation}
  Q_n(t, h_n) = \int_\mathbb{R} A_{n,t}(y, x)dy
\end{equation}
$$
qui est estimé sur $N$ valeurs de $x$:
$$
\begin{equation}
  Q_n(t, h_n) = \frac{1}{N}\sum\limits_{i=1}^{N}\int_\mathbb{R} A_{n,t}(y, x_i)dy, x \in \mathcal{X}^N 
\end{equation}
$$

$$
\begin{equation}
  J_n(h) = \sum\limits_{t=1}^n Q_n(t, h) 
\end{equation}
$$
$$
\begin{equation}
  h_n^* = \argmin_{h>0} J_n(h)
\end{equation}
$$

```{r}
# h_range <- seq(0, 1, 0.1)
# N=1
# n <- NROW(X)
# X <- data.frame(X)
# # J(0.1)
# res <- sapply(h_range, J) #/!\ charger les fonctions Q et J avant
# res <- readRDS("minimisation_J.RDS")  #evite 8-9 minutes de calculs
# plot(h_range, res, type = 'b')
```


```{r}
#parametres
h_n <- 0.85

#estimation de q_n et calcul de q
x_range <- seq(-2, 2, length.out = n/2)
parallel::mclapply(x_range, function(x){
  q <- qnorm(p = alpha, mean = x^2, sd = 1)
  q_n <- conditionnal_quantile(X, Y, x, alpha, h_n = h_n)
  data.frame(q=q, q_n=q_n)
}, mc.cores = 8) %>% bind_rows()-> res

#plot
res <- cbind(x_range = x_range, res) %>% 
  gather(key = key, value = value, -x_range)
data <- cbind(data.frame(X=X, Y=Y), res) 

ggplot(data) +
  geom_point(aes(x=X, y=Y)) +
  geom_line(aes(x=x_range, y=value, col = key)) +
  ggtitle(paste("h_n =", h_n))
```

##Autres questions

* Le code marche aussi pour k>1?
* Validation croisé pour k>1 avec un vecteur h_n
* Estimation par produit de noyau? C'est deja lourd de calculer un h_n
* SIR quand k grand? ou autre technique de reduction dimensionnelle
* biblio a jour? Pas de nouvelle technique miracle depuis 2006?

